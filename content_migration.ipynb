{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURE HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CONSTANTS\"\"\" \n",
    "\n",
    "CATALOG_ID = \"\"\n",
    "ORIGIN_TRANSFER_USER = \"\"\n",
    "ORIGIN_URL = \"\"\n",
    "ITEM_ID = \"\" # INSERT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"IMPORTS\"\"\"\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.gis import Item\n",
    "from arcgis import __version__\n",
    "from arcgis.features import FeatureLayerCollection, Table\n",
    "from arcgis.mapping import WebMap\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "import uuid\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ITEM_COPY_PROPERTIES = ['title', 'type', 'typeKeywords', 'description', 'tags',\n",
    "                        'snippet', 'extent', 'spatialReference', 'name',\n",
    "                        'accessInformation', 'licenseInfo', 'culture', 'url']\n",
    "\n",
    "TEXT_BASED_ITEM_TYPES = frozenset(['Web Map', 'Feature Service', 'Map Service','Web Scene', 'Dashboard',\n",
    "                                   'Image Service', 'Feature Collection', \n",
    "                                   'Feature Collection Template',\n",
    "                                   'Web Mapping Application', 'Mobile Application', \n",
    "                                   'Symbol Set', 'Color Set',\n",
    "                                   'Windows Viewer Configuration'])\n",
    "\n",
    "FILE_BASED_ITEM_TYPES = frozenset(['File Geodatabase','CSV', 'Image', 'KML', 'Locator Package',\n",
    "                                  'Map Document', 'Shapefile', 'Microsoft Word', 'PDF',\n",
    "                                  'Microsoft Powerpoint', 'Microsoft Excel', 'Layer Package',\n",
    "                                  'Mobile Map Package', 'Geoprocessing Package', 'Scene Package',\n",
    "                                  'Tile Package', 'Vector Tile Package'])\n",
    "\n",
    "RELATIONSHIP_TYPES = frozenset(['Map2Service', 'WMA2Code',\n",
    "                                'Map2FeatureCollection', 'MobileApp2Code', 'Service2Data',\n",
    "                                'Service2Service'])\n",
    "\n",
    "_version = [int(i) for i in __version__.split('.')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIGURE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting ...\n",
      "Connection Successful.\n",
      "Logged into portal as: ArcGISAutomotive\n",
      "Connection Successful.\n",
      "Logged into portal as: arcgis_automotive\n"
     ]
    }
   ],
   "source": [
    "### HARDCODED CONFIG FOR TESTING SM TRANSFER\n",
    "\n",
    "origin_pass = getpass(prompt=f\"Enter the password for user {ORIGIN_TRANSFER_USER}: \")\n",
    "\n",
    "# Establish origin and target GIS organizations\n",
    "print(\"Connecting ...\")\n",
    "origin = GIS(ORIGIN_URL, ORIGIN_TRANSFER_USER, origin_pass, expiration=9999)\n",
    "print(\"Connection Successful.\")\n",
    "\n",
    "destination = GIS(\"home\", expiration=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = destination.content.get(CATALOG_ID)\n",
    "catalog = catalog.tables[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_folder(gis, folder_name):\n",
    "    # Check if the folder exists\n",
    "    folders = gis.users.me.folders\n",
    "    existing_folder = next((f for f in folders if f['title'] == folder_name), None)\n",
    "\n",
    "    if existing_folder:\n",
    "        print(f\"Folder '{folder_name}' already exists.\")\n",
    "        return existing_folder\n",
    "    else:\n",
    "        # Create the folder\n",
    "        new_folder = gis.content.create_folder(folder_name)\n",
    "        print(f\"Folder '{folder_name}' created successfully.\")\n",
    "        return new_folder\n",
    "\n",
    "#Get the specified item as an object and then get the title\n",
    "item_origin = origin.content.get(ITEM_ID)\n",
    "fldr_name = get_or_create_folder(destination, item_origin.title)\n",
    "\n",
    "def export_resources(item, save_path=None, file_name=None):\n",
    "    \"\"\"\n",
    "    Helper function, from https://developers.arcgis.com/python/samples/clone-storymap-version2/\n",
    "    Export's the data's resources as a zip file\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f'{item._gis._portal.resturl}content/users/{item._user_id}/items/{item.itemid}/resources/export'\n",
    "    if save_path is None:\n",
    "        save_path = tempfile.gettempdir()\n",
    "    if file_name is None:\n",
    "        file_name = f\"{uuid.uuid4().hex[:6]}.zip\"\n",
    "    params = {'f' : 'zip'}\n",
    "    con = item._gis._portal.con\n",
    "    resources = con.get(url, params=params,\n",
    "                        out_folder=save_path,\n",
    "                        file_name=file_name,\n",
    "                        try_json=False)\n",
    "    return resources\n",
    "\n",
    "def get_layer_item_ids(wm) -> list:\n",
    "    \"\"\"\n",
    "    Helper function from https://developers.arcgis.com/python/guide/cloning-content/\n",
    "    \n",
    "    Returns the related items in a webmap.\n",
    "    \n",
    "    Params:\n",
    "        wm (argis.gis.Item): Webmap item to be inspected.\n",
    "    Returns:\n",
    "        wm_id_list (list): List of related items in the web map.\n",
    "    \"\"\"\n",
    "    wmo = WebMap(wm)\n",
    "    wm_id_list = []\n",
    "    \n",
    "    for layer in wmo.layers:\n",
    "        try:\n",
    "            fsvc = FeatureLayerCollection(layer['url'][:-1], origin)\n",
    "            if not fsvc.properties['serviceItemId'] in wm_id_list:\n",
    "                wm_id_list.append(fsvc.properties['serviceItemId'])\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    return wm_id_list\n",
    "\n",
    "def iterate_all(iterable, returned=\"key\"):\n",
    "    # Credits: https://gist.github.com/PatrikHlobil/9d045e43fe44df2d5fd8b570f9fd78cc\n",
    "    \n",
    "    \"\"\"Returns an iterator that returns all keys or values\n",
    "       of a (nested) iterable.\n",
    "       \n",
    "       Arguments:\n",
    "           - iterable: <list> or <dictionary>\n",
    "           - returned: <string> \"key\" or \"value\"\n",
    "           \n",
    "       Returns:\n",
    "           - <iterator>\n",
    "    \"\"\"\n",
    "  \n",
    "    if isinstance(iterable, dict):\n",
    "        for key, value in iterable.items():\n",
    "            if returned == \"key\":\n",
    "                yield key\n",
    "            elif returned == \"value\":\n",
    "                if not (isinstance(value, dict) or isinstance(value, list)):\n",
    "                    yield value\n",
    "            else:\n",
    "                raise ValueError(\"'returned' keyword only accepts 'key' or 'value'.\")\n",
    "            for ret in iterate_all(value, returned=returned):\n",
    "                yield ret\n",
    "    elif isinstance(iterable, list):\n",
    "        for el in iterable:\n",
    "            for ret in iterate_all(el, returned=returned):\n",
    "                yield ret\n",
    "\n",
    "def get_dash_wm(dash) -> list:\n",
    "    \"\"\"\n",
    "    From https://developers.arcgis.com/python/guide/cloning-content/#helper-functions\n",
    "    \n",
    "    Returns a list of all Web Maps participating in a Dashboard. \n",
    "    \n",
    "    Arguments:\n",
    "        dash (item): Dashboard to return participating Web Maps from.\n",
    "    Returns:\n",
    "        (list): All Web Maps partipating in the dashboard. \n",
    "    \n",
    "    \"\"\"\n",
    "    return [origin.content.get(widget['itemId']) \n",
    "            for widget in dash.get_data()[\"desktopView\"]['widgets']\n",
    "            if widget['type'] == \"mapWidget\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (2473722771.py, line 331)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\john7126\\AppData\\Local\\Temp\\1\\ipykernel_9852\\2473722771.py\"\u001b[1;36m, line \u001b[1;32m331\u001b[0m\n\u001b[1;33m    continue\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "def wc_transfer(destination: GIS, \n",
    "                records: Table = None, \n",
    "                items: list = [], \n",
    "                logging: bool = False) -> list:\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs a web content transfer of items from an origin to destination AGOL. \n",
    "    \n",
    "    Arguments:\n",
    "        destination (arcgis.gis.GIS): Destination GIS for the given items\n",
    "        items (list): a list of Items to be transferred.\n",
    "        records (Table): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "    \"\"\"\n",
    "    \n",
    "    origin_to_destination_ids = {}\n",
    "    \n",
    "    for item in items:\n",
    "        if item.owner != ORIGIN_TRANSFER_USER:\n",
    "            item.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "    \n",
    "    item_titles = [item.title for item in items]\n",
    "    \n",
    "    print(\"Performing Web Content transfer for the following items: \")\n",
    "    for title in item_titles:\n",
    "        print(title)\n",
    "        \n",
    "    for item in items:\n",
    "        try:\n",
    "            if item.groupDesignations == 'livingatlas' or 'livingatlas' in item.groupDesignations:\n",
    "                print(f\"{item.title} is a Living Atlas item and therefore can only be referenced, not copied. Removing it from transfer.\")\n",
    "                return\n",
    "            if 'Requires Subscription' in item.typeKeywords:\n",
    "                print(f\"{item.title} is a premium subscription item and therefore can only be referenced, not copied. Removing it from transfer.\")\n",
    "                return\n",
    "            if 'utility.arcgis.com/usrsvcs' in item.url:\n",
    "                print(f\"{item.title} is a referenced  item and therefore can only be referenced, not copied. Removing it from transfer.\")\n",
    "                return\n",
    "        except TypeError:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    me = destination.users.search(destination.properties.user.username)[0]\n",
    "    folders = [folder[\"title\"] for folder in me.folders]\n",
    " \n",
    "    for item in items:\n",
    "        if item.id == ITEM_ID and item.id not in folders:\n",
    "            destination.content.create_folder(fldr_name) ##Changed Folder\n",
    "                            \n",
    "    destination_items = destination.content.clone_items(items, folder=fldr_name) ##Changed Folder\n",
    "    \n",
    "    print(\"Item(s) cloned successfully. Updating tags ... \")\n",
    "    now = datetime.now()\n",
    "    tag = f\"src_{origin.properties['urlKey']}_{now.month}/{now.day}/{now.year}-{now.hour}:{now.minute}\"\n",
    "    \n",
    "    for item in destination_items:\n",
    "        item.update({'tags': tag})\n",
    "    for item, destitem in zip(items, destination_items):\n",
    "        destitem.update({'tags': item.tags})\n",
    "        \n",
    "    # build origin to destination map and memoize to catalog\n",
    "    origin_item_index = 0\n",
    "    for destination_item in destination_items:            \n",
    "        origin_to_destination_ids[item.id] = destination_item.id\n",
    "        \n",
    "        if item.id == ITEM_ID:\n",
    "            try:\n",
    "                destination_item.move(fldr_name) ##Changed Folder\n",
    "            except Exception:\n",
    "                continue\n",
    "                \n",
    "        if logging:   \n",
    "             \n",
    "            adds = {\"attributes\":\n",
    "                {\n",
    "                    \"source_id\": items[origin_item_index].id,\n",
    "                    \"destination_id\": destination_item.id,\n",
    "                    \"title\": destination_item.title,\n",
    "                    \"owner\": destination_item.owner,\n",
    "                    \"transfer_date\": str(datetime.now())\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            records.edit_features(adds=[adds])\n",
    "        \n",
    "        origin_item_index += 1\n",
    "        \n",
    "    print(\"Web Content Transfer complete.\")\n",
    "    \n",
    "    for item in destination_items:\n",
    "        try:\n",
    "            children = get_layer_item_ids(wm=item)\n",
    "            for child in children:\n",
    "                child_item = destination.content.get(child)\n",
    "                child_item.move(fldr_name) ##Changed Folder\n",
    "        except TypeError:\n",
    "            continue\n",
    "    \n",
    "    return destination_items\n",
    "    \n",
    "def dash_transfer(destination: GIS, \n",
    "                  dash: Item, \n",
    "                  swizzle: bool = True, \n",
    "                  records: Table = None, \n",
    "                  logging: bool = False) -> None:\n",
    "    \n",
    "    \"\"\"    \n",
    "    Performs a web content transfer of a dashboard to destination AGOL.\n",
    "    \n",
    "    Arguments:\n",
    "        destination (GIS): Destination GIS for the given Dashboard\n",
    "        dash (Item): A Dashboard item in the origin GIS\n",
    "        swizzle (bool): If True, enables JSON swizzling to map keys to values. Future proofing for ArcGIS API 2.2 release.\n",
    "        records (Table): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "    \"\"\"\n",
    "        \n",
    "    dash_elements = get_dash_wm(dash=dash)\n",
    "    wm_items = {} # origin to destination ids\n",
    "    \n",
    "    if dash.owner != ORIGIN_TRANSFER_USER:\n",
    "        dash.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "    \n",
    "    try:     \n",
    "        if dash.groupDesignations == 'livingatlas':\n",
    "            print(f\"{item.title} is a Living Atlas item and therefore can only be referenced, not copied. Aborting this dash transfer.\")\n",
    "            return\n",
    "        if 'Requires Subscription' in dash.typeKeywords:\n",
    "            print(f\"{item.title} is a premium subscription item and therefore can only be referenced, not copied. Aborting this dash transfer.\")\n",
    "            return\n",
    "    except TypeError:\n",
    "        # We pass here because a TypeError indicates that there are no issues with typeKeywords or none exist.\n",
    "        pass\n",
    "            \n",
    "    print(f\"Creating destination folder for dashboard {dash.title} ...\")\n",
    "    if dash.id == ITEM_ID:\n",
    "        destination.content.create_folder(fldr_name) ##Changed Folder\n",
    "    \n",
    "    for ele in dash_elements:\n",
    "        \n",
    "        if ele.owner != ORIGIN_TRANSFER_USER:\n",
    "            ele.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "                    \n",
    "        # if the item participating in the dashboard has not yet been cloned: \n",
    "        try:\n",
    "            print(f\"Transferring {ele.title} to destination org, moving to Web Content transfer workflow ... \")\n",
    "            wc = wc_transfer(destination=destination, items=[ele])\n",
    "            web_map_dest = [item.id for item in wc if item.type == \"Web Map\"]\n",
    "            wm_items[ele.id] = web_map_dest[0]\n",
    "            for item in wc:\n",
    "                print(f\"Moving {item.title} to folder {fldr_name}... \") ##Changed Folder\n",
    "                item.move(fldr_name) ##Changed Folder\n",
    "                       \n",
    "        except IndexError:\n",
    "            print(f\"Item {ele.title} has already been transferred, applying destination-side edits ... \")\n",
    "            ele_from_search = destination.content.search(query=f\"typekeywords:source-{ele.id}\")[0]\n",
    "            wm_items[ele.id] = ele_from_search.id\n",
    "            ele_from_search.move(fldr_name) ##Changed Folder\n",
    "\n",
    "    print(f\"Participating items handled, transferring dashboard {dash.title} ... \")\n",
    "\n",
    "    if swizzle == False:\n",
    "        dest_dash = destination.content.clone_items(items=[dash], item_mapping=wm_items, folder=fldr_name) ##Changed Folder\n",
    "    else:\n",
    "        dest_dash = destination.content.clone_items(items=[dash], folder=fldr_name) ##Changed Folder\n",
    "\n",
    "    \n",
    "    now = datetime.now()\n",
    "    tag = f\"src_{origin.properties['urlKey']}_{now.month}/{now.day}/{now.year}-{now.hour}:{now.minute}\"\n",
    "\n",
    "    for item in dest_dash:\n",
    "        item.update({'tags': tag})\n",
    "        item.update({'tags': dash.tags})\n",
    "    \n",
    "    if logging:\n",
    "        \n",
    "        adds = {\"attributes\":\n",
    "            {\n",
    "                \"source_id\": dash.id,\n",
    "                \"destination_id\": dest_dash[0].id,\n",
    "                \"title\": dest_dash[0].title,\n",
    "                \"owner\": dest_dash[0].owner,\n",
    "                \"transfer_date\": str(datetime.now())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        records.edit_features(adds=[adds])\n",
    "        \n",
    "    if swizzle:\n",
    "        # Swizzle the old and new IDs\n",
    "        cloned_dash = dest_dash[0]\n",
    "        dash_json = cloned_dash.get_data()\n",
    "        dash_str = json.dumps(dash_json)\n",
    "        \n",
    "        # build url dict\n",
    "        wm_urls_keys = []\n",
    "        wm_urls_vals = []\n",
    "        \n",
    "        # Swizzle Item IDs\n",
    "        for key, val in wm_items.items():\n",
    "            dash_str = dash_str.replace(key, val)\n",
    "        \n",
    "        updated_data = json.loads(dash_str)\n",
    "\n",
    "        cloned_dash.update(item_properties = {}, data = updated_data)\n",
    "\n",
    "        # re-init json data\n",
    "        dash_json = cloned_dash.get_data()\n",
    "        dash_str = json.dumps(dash_json)\n",
    "        \n",
    "        # Swizzle Feature Service URLs\n",
    "        for key, val in wm_items.items():\n",
    "            origin_wm = origin.content.get(key)\n",
    "            origin_wm = WebMap(origin_wm)\n",
    "            \n",
    "            dest_wm = destination.content.get(val)\n",
    "            dest_wm = WebMap(dest_wm)\n",
    "            \n",
    "            for layer in origin_wm.layers:\n",
    "                wm_urls_keys.append(layer[\"url\"])\n",
    "            for layer in dest_wm.layers:\n",
    "                wm_urls_vals.append(layer[\"url\"])\n",
    "        \n",
    "        fs_url_dict = dict(zip(wm_urls_keys, wm_urls_vals))\n",
    "        \n",
    "        for key, val in fs_url_dict.items():\n",
    "            dash_str.replace(key, val)\n",
    "        \n",
    "        updated_data = json.loads(dash_str)\n",
    "        cloned_dash.update(item_properties = {}, data = updated_data)\n",
    "\n",
    "    print(f\"Dashboard clone successful. Refresh your content page.\")\n",
    "\n",
    "def sm_transfer(destination: GIS,  \n",
    "                item: Item,\n",
    "                records: Table = None, \n",
    "                logging : bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Adapted code sample from https://developers.arcgis.com/python/samples/clone-storymap-version2/\n",
    "    \n",
    "    Transfer protocol for Story Maps and their web content items. Does not call copy_items() as protocol is different for this content.\n",
    "    \n",
    "    Arguments:\n",
    "        destination (GIS): Destination GIS for the origin item.\n",
    "        item (Item): Story Map item to transfer from the origin.\n",
    "        records (Table): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    story_map = item\n",
    "    \n",
    "    orig_thumbnail = story_map.download_thumbnail()\n",
    "    \n",
    "    if story_map.id == ITEM_ID:\n",
    "        destination.content.create_folder(fldr_name) ##Changed Folder  \n",
    "    \n",
    "    # check version to apply relevant protocol\n",
    "    if _version <= [1, 8, 2]:\n",
    "        resource = export_resources(item=story_map)\n",
    "    else:\n",
    "        resource = story_map.resources.export()\n",
    "\n",
    "    # get story map item data from json to store related maps\n",
    "    story_map_json = story_map.get_data(try_json=True)\n",
    "\n",
    "    web_maps = set([v['data']['itemId'] for k, v in story_map_json['resources'].items() \\\n",
    "            if v['type'].lower().find('webmap')>-1])\n",
    "    express_maps = set([v['data']['itemId'] for k, v in story_map_json['resources'].items() \\\n",
    "            if v['type'].lower().find('expressmap')>-1])\n",
    "\n",
    "\n",
    "    webmap_mapper = {} # keys are origin IDs, values are destination IDs\n",
    "    for wm in web_maps:\n",
    "        webmap_to_copy = origin.content.get(wm)\n",
    "        \n",
    "        if webmap_to_copy == None:\n",
    "            print(f\"Webmap Item {wm.title} in Storymap not found in the org. Skipping...\")\n",
    "            continue\n",
    "        else:    \n",
    "            \n",
    "            cloned_webmaps = destination.content.clone_items([webmap_to_copy])\n",
    "            webmap_mapper[webmap_to_copy.id] = [i for i in cloned_webmaps if i.type == 'Web Map'][0].id\n",
    "\n",
    "            # memoize tranfer to catalog\n",
    "            if logging:\n",
    "                \n",
    "                adds = {\"attributes\":\n",
    "                    {\n",
    "                        \"source_id\": webmap_to_copy.id,\n",
    "                        \"destination_id\": webmap_mapper[webmap_to_copy.id],\n",
    "                        \"title\": webmap_to_copy.title,\n",
    "                        \"owner\": webmap_to_copy.owner,\n",
    "                        \"type\": webmap_to_copy.type,\n",
    "                        \"transfer_date\": str(datetime.now())\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                records.edit_features(adds=[adds])\n",
    "                \n",
    "            for wm in cloned_webmaps:\n",
    "                try:\n",
    "                    wm.move(fldr_name) ##Changed Folder\n",
    "                except Exception:\n",
    "                    continue\n",
    "                \n",
    "    # remap the old itemid to the new one\n",
    "    story_map_text = json.dumps(story_map_json)\n",
    "\n",
    "    for key, val in webmap_mapper.items():\n",
    "        story_map_text = story_map_text.replace(key, val)\n",
    "\n",
    "    new_item = destination.content.add({'type' : story_map.type,\n",
    "                             'tags' : story_map.tags,\n",
    "                             'title' : story_map.title,\n",
    "                             'description' : story_map.description,\n",
    "                             'typeKeywords' : story_map.typeKeywords,\n",
    "                             'extent' : story_map.extent,\n",
    "                             'text' :story_map_text}\n",
    "                            )\n",
    "\n",
    "    # bring in the storymap resources exported to a zip archive earlier\n",
    "    new_item.resources.add(resource, archive=True)\n",
    "\n",
    "    # update the url\n",
    "    new_item.update({'url': story_map.url.replace(story_map.id, new_item.id)})\n",
    "    new_item.update(thumbnail=orig_thumbnail)\n",
    "    \n",
    "    try:\n",
    "        new_item.move(fldr_name) ##Changed Folder\n",
    "    except Exception:\n",
    "        print(f\"{new_item} could not be moved. Ensure folder name is correct.\")\n",
    "    \n",
    "    if logging:\n",
    "    \n",
    "        adds = {\"attributes\":\n",
    "            {\n",
    "                \"source_id\": item.id,\n",
    "                \"destination_id\": new_item[0].id,\n",
    "                \"title\": new_item[0].title,\n",
    "                \"owner\": new_item[0].owner,\n",
    "                \"type\": new_item[0].type,\n",
    "                \"transfer_date\": str(datetime.now())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        records.edit_features(adds=[adds])\n",
    "    \n",
    "    print(f\"StoryMap transfer complete. You can visit it at {new_item.homepage}\")\n",
    "\n",
    "def transfer():\n",
    "    \"\"\"\n",
    "    Runs the appropriate transfer function for the Item associated with the ITEM_ID global at the top of the notebook.\n",
    "    \"\"\"\n",
    "        \n",
    "    # reassign item to origin transfer user\n",
    "    if item_origin.owner != ORIGIN_TRANSFER_USER:\n",
    "        item_origin.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "    \n",
    "    # decide on appropriate workflow for item\n",
    "    if item_origin.type == \"StoryMap\":\n",
    "        sm_transfer(destination=destination, item=item_origin)\n",
    "    elif item_origin.type == \"Dashboard\":\n",
    "        dash_transfer(destination=destination, dash=item_origin, swizzle=True)\n",
    "    else:\n",
    "        wc_transfer(destination=destination, items=[item_origin])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer()"
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "8.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
