{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Script Version\n",
    "##### 19 April 2024 Commits\n",
    "##### Bug Out 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"IMPORTS\"\"\"\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.gis import Item\n",
    "from arcgis import __version__\n",
    "from arcgis.features import FeatureLayerCollection, Table\n",
    "from arcgis.apps.expbuilder import WebExperience\n",
    "from arcgis.mapping import WebMap\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "import uuid\n",
    "import json\n",
    "import tempfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURE TRANSFER HERE\n",
    "##Run this cell each time you update the item id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CONSTANTS\"\"\" \n",
    "\n",
    "ORIGIN_TRANSFER_USER = \"\" #Examples - ['truck_transfer', 'auto_transfer', 'manu_transfer','retail_transfer', 'realestate_transfer', 'realestate2_transfer']\n",
    "ITEM_ID = \"\" # INSERT HERE\n",
    "\n",
    "#Set to True if you want to have content moved to a different user in the destination\n",
    "REASSIGN = False\n",
    "#If REASSIGN is set to True then MOVE_TO has to be set to the username you want the items to go to in the destination org\n",
    "MOVE_TO = '' #Example - john7126@esri.com_esri_cgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run only at start up \n",
    "### TRANSFER CODE (Run this the first time you open the notebook, but you don't need to run this section each time -- once you are logged in you don't need to re-run this each time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Connecting via named user\")\n",
    "origin_pass = getpass(prompt=f\"Enter the password for user {ORIGIN_TRANSFER_USER}: \")\n",
    "origin = GIS('https://www.arcgis.com', ORIGIN_TRANSFER_USER, origin_pass, expiration=9999)\n",
    "print(\"Connection Successful.\")\n",
    "print(\"Logged into portal as: \" + origin.properties.user.username)\n",
    "\n",
    "#Log into Destination \n",
    "o_url = origin.url\n",
    "print(f\"Attempting loging at AGOL with url {o_url}\")\n",
    "\n",
    "###Log in via named user method\n",
    "if any(keyword in o_url for keyword in ['manucomm', 'truckcomm', 'commteamretail', 'automotive', 'commre', 'commteamre']):\n",
    "    DESTINATION_TRANSFER_USER = \"cgs_transfer\"\n",
    "    print(f\"Logging in with {DESTINATION_TRANSFER_USER}\")\n",
    "    #destination_pass = getpass(prompt=f\"Enter the password for user {DESTINATION_TRANSFER_USER}: \")\n",
    "    destination_pass = origin_pass\n",
    "    DESTINATION_URL = \"https://esri-cgs.maps.arcgis.com/\"\n",
    "    CATALOG_ID = \"9f82678130ef47aeb942bf87ab99a3eb\"\n",
    "    destination = GIS(DESTINATION_URL, DESTINATION_TRANSFER_USER, destination_pass, expiration=9999)\n",
    "    print(\"Successfully logged in as: \" + destination.properties.user.username)\n",
    "elif any(keyword in o_url for keyword in ['banking', 'inscomm']):\n",
    "    DESTINATION_TRANSFER_USER = \"fsi_transfer\"\n",
    "    print(f\"Logging in with {DESTINATION_TRANSFER_USER}:\")\n",
    "    #destination_pass = getpass(prompt=f\"Enter the password for user {DESTINATION_TRANSFER_USER}: \")\n",
    "    destination_pass = origin_pass\n",
    "    DESTINATION_URL = \"https://fsi.maps.arcgis.com/\"\n",
    "    CATALOG_ID = \"98c72904ee4640a5b3707ee6f2dd1246\"\n",
    "    destination = GIS(DESTINATION_URL, DESTINATION_TRANSFER_USER, destination_pass, expiration=9999)\n",
    "    print(\"Successfully logged in as: \" + destination.properties.user.username)\n",
    "else:\n",
    "    DESTINATION_URL = input(\"Enter the portal URL for the destination portal: \")\n",
    "    DESTINATION_TRANSFER_USER = input(\"Enter the username for the destination portal: \")\n",
    "    destination_pass = getpass(prompt=f\"Enter the password for user {DESTINATION_TRANSFER_USER}: \")\n",
    "    CATALOG_ID = input(\"Enter the catalog itemid from the destination portal: \")\n",
    "    destination = GIS(DESTINATION_URL, DESTINATION_TRANSFER_USER, destination_pass, expiration=9999)\n",
    "    print(\"Successfully logged in as: \" + destination.properties.user.username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_COPY_PROPERTIES = ['title', 'type', 'typeKeywords', 'description', 'tags',\n",
    "                        'snippet', 'extent', 'spatialReference', 'name',\n",
    "                        'accessInformation', 'licenseInfo', 'culture', 'url']\n",
    "\n",
    "TEXT_BASED_ITEM_TYPES = frozenset(['Web Map', 'Feature Service', 'Map Service','Web Scene', 'Dashboard',\n",
    "                                   'Image Service', 'Feature Collection', \n",
    "                                   'Feature Collection Template',\n",
    "                                   'Web Mapping Application', 'Mobile Application', \n",
    "                                   'Symbol Set', 'Color Set',\n",
    "                                   'Windows Viewer Configuration'])\n",
    "\n",
    "FILE_BASED_ITEM_TYPES = frozenset(['File Geodatabase','CSV', 'Image', 'KML', 'Locator Package',\n",
    "                                  'Map Document', 'Shapefile', 'Microsoft Word', 'PDF',\n",
    "                                  'Microsoft Powerpoint', 'Microsoft Excel', 'Layer Package',\n",
    "                                  'Mobile Map Package', 'Geoprocessing Package', 'Scene Package',\n",
    "                                  'Tile Package', 'Vector Tile Package'])\n",
    "\n",
    "RELATIONSHIP_TYPES = frozenset(['Map2Service', 'WMA2Code',\n",
    "                                'Map2FeatureCollection', 'MobileApp2Code', 'Service2Data',\n",
    "                                'Service2Service'])\n",
    "\n",
    "_version = [int(i) for i in __version__.split('.')]\n",
    "\n",
    "#Set to False to keep items in the Origin Org in place. True is the default.\n",
    "MOVE_ITEMS = True\n",
    "\n",
    "#Create or get folder in destination user content\n",
    "def get_or_create_folder(gis: GIS, folder_name: str, user: str) -> str:\n",
    "    # Check if the folder exists\n",
    "    folders = gis.users.get(user).folders\n",
    "    existing_folder = next((f for f in folders if f['title'] == folder_name), None)\n",
    "\n",
    "    if existing_folder:\n",
    "        print(f\"Folder '{folder_name}' already exists.\")\n",
    "        return folder_name\n",
    "    else:\n",
    "        # Create the folder\n",
    "        new_folder = gis.content.create_folder(folder_name)\n",
    "        print(f\"Folder '{folder_name}' created successfully.\")\n",
    "        return folder_name\n",
    "\n",
    "#Get the specified item as an object and then get the title\n",
    "item_origin = origin.content.get(ITEM_ID)\n",
    "fldr_name = get_or_create_folder(destination, item_origin.title, destination.properties.user.username)\n",
    "\n",
    "def export_resources(item, save_path=None, file_name=None):\n",
    "    \"\"\"\n",
    "    Helper function, from https://developers.arcgis.com/python/samples/clone-storymap-version2/\n",
    "    Export's the data's resources as a zip file\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f'{item._gis._portal.resturl}content/users/{item._user_id}/items/{item.itemid}/resources/export'\n",
    "    if save_path is None:\n",
    "        save_path = tempfile.gettempdir()\n",
    "    if file_name is None:\n",
    "        file_name = f\"{uuid.uuid4().hex[:6]}.zip\"\n",
    "    params = {'f' : 'zip'}\n",
    "    con = item._gis._portal.con\n",
    "    resources = con.get(url, params=params,\n",
    "                        out_folder=save_path,\n",
    "                        file_name=file_name,\n",
    "                        try_json=False)\n",
    "    return resources\n",
    "\n",
    "def get_layer_item_ids(wm) -> list:\n",
    "    \"\"\"\n",
    "    Helper function from https://developers.arcgis.com/python/guide/cloning-content/\n",
    "    \n",
    "    Returns the related items in a webmap.\n",
    "    \n",
    "    Params:\n",
    "        wm (argis.gis.Item): Webmap item to be inspected.\n",
    "    Returns:\n",
    "        wm_id_list (list): List of related items in the web map.\n",
    "    \"\"\"\n",
    "    wmo = WebMap(wm)\n",
    "    wm_id_list = []\n",
    "    \n",
    "    for layer in wmo.layers:\n",
    "        try:\n",
    "            fsvc = FeatureLayerCollection(layer['url'][:-1], origin)\n",
    "            if not fsvc.properties['serviceItemId'] in wm_id_list:\n",
    "                wm_id_list.append(fsvc.properties['serviceItemId'])\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    return wm_id_list\n",
    "\n",
    "def flatten_json(y):\n",
    "    out = {}\n",
    " \n",
    "    def flatten(x, name=''):\n",
    " \n",
    "        # If the Nested key-value\n",
    "        # pair is of dict type\n",
    "        if type(x) is dict:\n",
    " \n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    " \n",
    "        # If the Nested key-value\n",
    "        # pair is of list type\n",
    "        elif type(x) is list:\n",
    " \n",
    "            i = 0\n",
    " \n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    " \n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "def get_dash_wm(dash) -> list:\n",
    "    \"\"\"\n",
    "    From https://developers.arcgis.com/python/guide/cloning-content/#helper-functions\n",
    "    Returns a list of all Web Maps participating in a Dashboard. \n",
    "    Arguments:\n",
    "        dash (item): Dashboard to return participating Web Maps from.\n",
    "    Returns:\n",
    "        (list): All Web Maps partipating in the dashboard. \n",
    "    \"\"\"\n",
    "    \n",
    "    dash_json = dash.get_data()\n",
    "    flattened_dash = flatten_json(dash_json)\n",
    "    \n",
    "    webmap_list = []\n",
    "    \n",
    "    for k, v in flattened_dash.items():\n",
    "        if 'itemId' in k:\n",
    "            item = origin.content.get(v)\n",
    "            if item.type == 'Web Map' and item not in webmap_list:\n",
    "                webmap_list.append(item)\n",
    "    \n",
    "    print(webmap_list)\n",
    "    return webmap_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_transfer(destination: GIS, \n",
    "                records: Table = None, \n",
    "                items: list = [], \n",
    "                logging: bool = False) -> list:\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs a web content transfer of items from an origin to destination AGOL. \n",
    "    \n",
    "    Arguments:\n",
    "        destination (arcgis.gis.GIS): Destination GIS for the given items\n",
    "        items (list): a list of Items to be transferred.\n",
    "        records (Table): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "    \"\"\"\n",
    "    \n",
    "    origin_to_destination_ids = {}\n",
    "    \n",
    "    for item in items:\n",
    "        if item.owner != ORIGIN_TRANSFER_USER and MOVE_ITEMS:\n",
    "            item.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "    \n",
    "    item_titles = [item.title for item in items]\n",
    "    \n",
    "    print(\"Performing Web Content transfer for the following items: \")\n",
    "    for title in item_titles:\n",
    "        print(f'>> {title}')\n",
    "        \n",
    "    for item in items:\n",
    "        try:\n",
    "            if item.groupDesignations == 'livingatlas' or 'livingatlas' in item.groupDesignations:\n",
    "                print(f\"{item.title} is a Living Atlas item and therefore can only be referenced, not copied. Removing it from transfer.\")\n",
    "                return\n",
    "            if 'Requires Subscription' in item.typeKeywords:\n",
    "                print(f\"{item.title} is a premium subscription item and therefore can only be referenced, not copied. Removing it from transfer.\")\n",
    "                return\n",
    "            if 'utility.arcgis.com/usrsvcs' in item.url:\n",
    "                print(f\"{item.title} is a referenced  item and therefore can only be referenced, not copied. Removing it from transfer.\")\n",
    "                return\n",
    "        except TypeError:\n",
    "            continue\n",
    "                                \n",
    "    destination_items = destination.content.clone_items(items, folder=fldr_name) ##Changed Folder\n",
    "    \n",
    "    print(\"Web Content transfer: Item(s) cloned successfully. Updating tags ... \")\n",
    "    now = datetime.now()\n",
    "    tag = f\"src_{origin.properties['urlKey']}_{now.month}/{now.day}/{now.year}-{now.hour}:{now.minute}\"\n",
    "    \n",
    "    for item in destination_items:\n",
    "        item.update({'tags': tag})\n",
    "    for item, destitem in zip(items, destination_items):\n",
    "        destitem.update({'tags': item.tags})\n",
    "        \n",
    "    # build origin to destination map and memoize to catalog\n",
    "    origin_item_index = 0\n",
    "    for destination_item in destination_items:            \n",
    "        origin_to_destination_ids[item.id] = destination_item.id\n",
    "        \n",
    "        if item.id == ITEM_ID:\n",
    "            try:\n",
    "                destination_item.move(fldr_name) ##Changed Folder\n",
    "            except Exception:\n",
    "                continue\n",
    "                \n",
    "        if logging:   \n",
    "            \n",
    "            try:\n",
    "                adds = {\"attributes\":\n",
    "                    {\n",
    "                        \"source_id\": items[origin_item_index].id,\n",
    "                        \"destination_id\": destination_item.id,\n",
    "                        \"title\": destination_item.title,\n",
    "                        \"owner\": destination_item.owner,\n",
    "                        \"transfer_date\": str(datetime.now())\n",
    "                    }\n",
    "                }\n",
    "            except IndexError:\n",
    "                print(f\"failed to log {destination_item.title}. Item was still brought over to destination.\")\n",
    "            \n",
    "            records.edit_features(adds=[adds])\n",
    "        \n",
    "        origin_item_index += 1\n",
    "        \n",
    "    print(\"Web Content Transfer: complete.\")\n",
    "    \n",
    "    for item in destination_items:\n",
    "        try:\n",
    "            children = get_layer_item_ids(wm=item)\n",
    "            for child in children:\n",
    "                child_item = destination.content.get(child)\n",
    "                child_item.move(fldr_name) ##Changed Folder\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        \n",
    "    me = destination.properties.user\n",
    "    items_in_folder = me.items(folder=fldr_name)\n",
    "    folder_item_ids = {item['title']: item['id'] for item in items_in_folder}\n",
    "    folder_item_urls = {item['title']: item['url'] for item in items_in_folder}\n",
    "    \n",
    "    \n",
    "    # Swizzling\n",
    "    for item in destination_items:\n",
    "        if item.type == \"Web Map\":\n",
    "            wm = WebMap(item)\n",
    "            for layer in wm.layers:\n",
    "                if \"layers\" in layer and layer[\"title\"] == \"Group Layer\":\n",
    "                    for sub_layer in layer[\"layers\"]:\n",
    "                        sub_layer_title = sub_layer['title']\n",
    "                        sub_layer['url'] = folder_item_urls[sub_layer_title]\n",
    "                        sub_layer['itemId'] = folder_item_ids[sub_layer_title]\n",
    "            wm.update()\n",
    "\n",
    "    return destination_items\n",
    "    \n",
    "def dash_transfer(destination: GIS, \n",
    "                  dash: Item, \n",
    "                  swizzle: bool = True, \n",
    "                  records: Table = None, \n",
    "                  logging: bool = False) -> None:\n",
    "    \n",
    "    \"\"\"    \n",
    "    Performs a web content transfer of a dashboard to destination AGOL.\n",
    "    \n",
    "    Arguments:\n",
    "        destination (GIS): Destination GIS for the given Dashboard\n",
    "        dash (Item): A Dashboard item in the origin GIS\n",
    "        swizzle (bool): If True, enables JSON swizzling to map keys to values. Future proofing for ArcGIS API 2.2 release.\n",
    "        records (Table): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "    \"\"\"\n",
    "        \n",
    "    dash_elements = get_dash_wm(dash=dash)\n",
    "    wm_items = {} # origin to destination ids\n",
    "    \n",
    "    if dash.owner != ORIGIN_TRANSFER_USER and MOVE_ITEMS:\n",
    "        dash.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "    \n",
    "    try:     \n",
    "        if dash.groupDesignations == 'livingatlas':\n",
    "            print(f\"{item.title} is a Living Atlas item and therefore can only be referenced, not copied. Aborting this dash transfer.\")\n",
    "            return\n",
    "        if 'Requires Subscription' in dash.typeKeywords:\n",
    "            print(f\"{item.title} is a premium subscription item and therefore can only be referenced, not copied. Aborting this dash transfer.\")\n",
    "            return\n",
    "    except TypeError:\n",
    "        # We pass here because a TypeError indicates that there are no issues with typeKeywords or none exist.\n",
    "        pass\n",
    "            \n",
    "    print(f\"Creating destination folder for Dashboard {dash.title} ...\")\n",
    "    if dash.id == ITEM_ID:\n",
    "        destination.content.create_folder(fldr_name) ##Changed Folder\n",
    "    \n",
    "    \n",
    "    dash_elements = list(set(dash_elements))\n",
    "    for ele in dash_elements:\n",
    "        \n",
    "        ele_itm = origin.content.get(ele)\n",
    "        if ele_itm.owner != ORIGIN_TRANSFER_USER and MOVE_ITEMS:\n",
    "            ele_itm.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "                    \n",
    "        # if the item participating in the dashboard has not yet been cloned: \n",
    "        try:\n",
    "            print(f\"Transferring {ele_itm.title} to destination org, moving to Web Content transfer workflow ... \")\n",
    "            wc = wc_transfer(destination=destination, items=[ele_itm])\n",
    "                       \n",
    "        except IndexError:\n",
    "            print(f\"Item {ele.title} has already been transferred, applying destination-side edits ... \")\n",
    "            ele_from_search = destination.content.search(query=f\"typekeywords:source-{ele.id}\")[0]\n",
    "            wm_items[ele.id] = ele_from_search.id\n",
    "            ele_from_search.move(fldr_name) ##Changed Folder\n",
    "\n",
    "    print(f\"Participating items handled, transferring dashboard {dash.title} ... \")\n",
    "\n",
    "    if swizzle == False:\n",
    "        dest_dash = destination.content.clone_items(items=[dash], item_mapping=wm_items, folder=fldr_name) ##Changed Folder\n",
    "    else:\n",
    "        dest_dash = destination.content.clone_items(items=[dash], folder=fldr_name) ##Changed Folder\n",
    "\n",
    "    \n",
    "    now = datetime.now()\n",
    "    tag = f\"src_{origin.properties['urlKey']}_{now.month}/{now.day}/{now.year}-{now.hour}:{now.minute}\"\n",
    "\n",
    "    for item in dest_dash:\n",
    "        item.update({'tags': tag})\n",
    "        item.update({'tags': dash.tags})\n",
    "    \n",
    "    if logging:\n",
    "        \n",
    "        adds = {\"attributes\":\n",
    "            {\n",
    "                \"source_id\": dash.id,\n",
    "                \"destination_id\": dest_dash[0].id,\n",
    "                \"title\": dest_dash[0].title,\n",
    "                \"owner\": dest_dash[0].owner,\n",
    "                \"transfer_date\": str(datetime.now())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        records.edit_features(adds=[adds])\n",
    "        \n",
    "    if swizzle:\n",
    "        # Swizzle the old and new IDs\n",
    "        cloned_dash = dest_dash[0]\n",
    "        dash_json = cloned_dash.get_data()\n",
    "        dash_str = json.dumps(dash_json)\n",
    "        \n",
    "        # build url dict\n",
    "        wm_urls_keys = []\n",
    "        wm_urls_vals = []\n",
    "        \n",
    "        # Swizzle Item IDs\n",
    "        for key, val in wm_items.items():\n",
    "            dash_str = dash_str.replace(key, val)\n",
    "        \n",
    "        updated_data = json.loads(dash_str)\n",
    "\n",
    "        cloned_dash.update(item_properties = {}, data = updated_data)\n",
    " \n",
    "        # Swizzle Feature Service URLs\n",
    "        for key, val in wm_items.items():\n",
    "            origin_wm = origin.content.get(key)\n",
    "            origin_wm = WebMap(origin_wm)\n",
    "            \n",
    "            dest_wm = destination.content.get(val)\n",
    "            dest_wm = WebMap(dest_wm)\n",
    "            \n",
    "            for layer in origin_wm.layers:\n",
    "                wm_urls_keys.append(layer[\"url\"])\n",
    "            for layer in dest_wm.layers:\n",
    "                wm_urls_vals.append(layer[\"url\"])\n",
    "        \n",
    "        fs_url_dict = dict(zip(wm_urls_keys, wm_urls_vals))\n",
    "        \n",
    "        for key, val in fs_url_dict.items():\n",
    "            dash_str.replace(key, val)\n",
    "        \n",
    "        updated_data = json.loads(dash_str)\n",
    "        cloned_dash.update(item_properties = {}, data = updated_data)\n",
    "\n",
    "    print(f\"Dashboard Transfer: clone of Dashboard {cloned_dash.title} to folder {fldr_name} complete.\")\n",
    "\n",
    "def sm_transfer(destination: GIS,  \n",
    "                item: Item,\n",
    "                records: Table = None, \n",
    "                logging : bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Adapted code sample from https://developers.arcgis.com/python/samples/clone-storymap-version2/\n",
    "    \n",
    "    Transfer protocol for Story Maps and their web content items. Does not call copy_items() as protocol is different for this content.\n",
    "    \n",
    "    Arguments:\n",
    "        destination (GIS): Destination GIS for the origin item.\n",
    "        item (Item): Story Map item to transfer from the origin.\n",
    "        records (Table): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "    \"\"\"\n",
    "    \n",
    "    story_map = item\n",
    "    \n",
    "    orig_thumbnail = story_map.download_thumbnail()\n",
    "    \n",
    "    if story_map.id == ITEM_ID:\n",
    "        destination.content.create_folder(fldr_name) ##Changed Folder  \n",
    "    \n",
    "    # check version to apply relevant protocol\n",
    "    if _version <= [1, 8, 2]:\n",
    "        resource = export_resources(item=story_map)\n",
    "    else:\n",
    "        resource = story_map.resources.export()\n",
    "\n",
    "    # get story map item data from json to store related maps\n",
    "    story_map_json = story_map.get_data(try_json=True)\n",
    "\n",
    "    web_maps = set([v['data']['itemId'] for k, v in story_map_json['resources'].items() \\\n",
    "            if v['type'].lower().find('webmap')>-1])\n",
    "    express_maps = set([v['data']['itemId'] for k, v in story_map_json['resources'].items() \\\n",
    "            if v['type'].lower().find('expressmap')>-1])\n",
    "\n",
    "\n",
    "    webmap_mapper = {} # keys are origin IDs, values are destination IDs\n",
    "    for wm in web_maps:\n",
    "        webmap_to_copy = origin.content.get(wm)\n",
    "        \n",
    "        if webmap_to_copy == None:\n",
    "            print(f\"Webmap Item {wm.title} in Storymap not found in the org. Skipping...\")\n",
    "            continue\n",
    "        else:    \n",
    "            \n",
    "            cloned_webmaps = destination.content.clone_items([webmap_to_copy])\n",
    "            webmap_mapper[webmap_to_copy.id] = [i for i in cloned_webmaps if i.type == 'Web Map'][0].id\n",
    "\n",
    "            # memoize tranfer to catalog\n",
    "            if logging:\n",
    "                \n",
    "                adds = {\"attributes\":\n",
    "                    {\n",
    "                        \"source_id\": webmap_to_copy.id,\n",
    "                        \"destination_id\": webmap_mapper[webmap_to_copy.id],\n",
    "                        \"title\": webmap_to_copy.title,\n",
    "                        \"owner\": webmap_to_copy.owner,\n",
    "                        \"type\": webmap_to_copy.type,\n",
    "                        \"transfer_date\": str(datetime.now())\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                records.edit_features(adds=[adds])\n",
    "                \n",
    "            for wm in cloned_webmaps:\n",
    "                try:\n",
    "                    wm.move(fldr_name) ##Changed Folder\n",
    "                except Exception:\n",
    "                    continue\n",
    "                \n",
    "    # remap the old itemid to the new one\n",
    "    story_map_text = json.dumps(story_map_json)\n",
    "\n",
    "    for key, val in webmap_mapper.items():\n",
    "        story_map_text = story_map_text.replace(key, val)\n",
    "\n",
    "    new_item = destination.content.add({'type' : story_map.type,\n",
    "                             'tags' : story_map.tags,\n",
    "                             'title' : story_map.title,\n",
    "                             'description' : story_map.description,\n",
    "                             'typeKeywords' : story_map.typeKeywords,\n",
    "                             'extent' : story_map.extent,\n",
    "                             'text' :story_map_text}\n",
    "                            )\n",
    "    \n",
    "    # bring in the storymap resources exported to a zip archive earlier\n",
    "    new_item.resources.add(resource, archive=True)\n",
    "\n",
    "    # update the url\n",
    "    new_item.update({'url': story_map.url.replace(story_map.id, new_item.id)})\n",
    "    new_item.update(thumbnail=orig_thumbnail)\n",
    "    \n",
    "    # set draft resources for the item\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", dir=tempfile.gettempdir(),\n",
    "                                     delete=False) as jsonfile:\n",
    "        jsonfile.write(json.dumps(new_item.get_data()))\n",
    "        new_item.resources.add(file=jsonfile.name)\n",
    "        type_keywords = [tk for tk in new_item.typeKeywords if 'smdraftresourceid' not in tk]\n",
    "        type_keywords.append(f'smdraftresourceid:{os.path.basename(jsonfile.name)}')\n",
    "        new_item.update({'typeKeywords': type_keywords})\n",
    "    \n",
    "    # express maps resources\n",
    "    if len(express_maps) > 0:\n",
    "        with tempfile.TemporaryDirectory() as d:\n",
    "            shutil.unpack_archive(filename=resource, extract_dir=d)\n",
    "            for expmap in express_maps:\n",
    "                express_draft = os.path.join(d, \"draft_\" + expmap)\n",
    "                express_pub = os.path.join(d, \"pub\" + expmap)\n",
    "                if os.path.isfile(express_pub):\n",
    "                    shutil.copy(express_pub, express_draft)\n",
    "                    new_item.resources.add(express_draft)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        new_item.move(fldr_name) ##Changed Folder\n",
    "    except Exception:\n",
    "        print(f\"{new_item} could not be moved. Ensure folder name is correct.\")\n",
    "    \n",
    "    if logging:\n",
    "    \n",
    "        adds = {\"attributes\":\n",
    "            {\n",
    "                \"source_id\": item.id,\n",
    "                \"destination_id\": new_item.id,\n",
    "                \"title\": new_item.title,\n",
    "                \"owner\": new_item.owner,\n",
    "                \"type\": new_item.type,\n",
    "                \"transfer_date\": str(datetime.now())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        records.edit_features(adds=[adds])\n",
    "    \n",
    "    print(f\"Transfer of Storymap {new_item.title} to {fldr_name} complete.\")\n",
    "\n",
    "def exb_transfer(destination: GIS,  \n",
    "                 exb: Item,\n",
    "                 records: Table = None, \n",
    "                 logging : bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Transfer protocol for Experience Builder items.\n",
    "    \n",
    "    Arguments:\n",
    "        destination (GIS): AGOL where the Experience is going to. \n",
    "        exb (Item): Experience Builder Item of interest.\n",
    "        records (Table): Table which memoizes the transfer of Experience items. \n",
    "        logging (bool): If True, enables the memoization of transfers. Requires records argument to be specified. \n",
    "    \"\"\"\n",
    "    \n",
    "    if exb.owner != ORIGIN_TRANSFER_USER and MOVE_ITEMS:\n",
    "        exb.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "        \n",
    "    experience = WebExperience(exb)\n",
    "    new_experience = experience.clone(target=destination, owner=destination.properties.user.username, folder=fldr_name)\n",
    "    \n",
    "    exb_json = new_experience.get_data()\n",
    "\n",
    "    old_embed_urls = []\n",
    "\n",
    "    for widget in exb_json['widgets']:\n",
    "            destination_embed_url = f'<p>{DESTINATION_URL}/apps/{new_embeds[widget].lower()}s/{new_embeds[widget].itemid}</p>'\n",
    "            if exb_json['widgets'][widget]['uri'] == 'widgets/common/embed/':\n",
    "                exb_json['widgets'][widget]['config']['expression'] = destination_embed_url\n",
    "\n",
    "    # need to remove  HTML tags so URLs can be used to grab item ids\n",
    "    old_embed_urls = [url.replace('<p>', \"%temp%\").replace(\"</p>\", \"\").replace(\"%temp%\", \"\") for url in old_embed_urls]\n",
    "    old_embed_list = [destination.content.get(url.rsplit('/', 1)[-1]) for url in old_embed_urls]\n",
    "    new_embeds = destination.content.clone_items(items=old_embed_list, folder=fldr_name)\n",
    "\n",
    "    for widget in exb_json['widgets']:\n",
    "        destination_embed_url = f'<p>{DESTINATION_URL}/apps/{new_embeds[widget].lower()}s/{new_embeds[widget].itemid}</p>'\n",
    "        if exb_json['widgets'][widget]['uri'] == 'widgets/common/embed/':\n",
    "            exb_json['widgets'][widget]['config']['expression'] = destination_embed_url\n",
    "    \n",
    "    new_experience.update(item_properties = {}, data = exb_json)\n",
    "    \n",
    "    if logging:\n",
    "        \n",
    "        adds = {\"attributes\":\n",
    "            {\n",
    "                \"source_id\": exb.id,\n",
    "                \"destination_id\": new_experience.id,\n",
    "                \"title\": new_experience.title,\n",
    "                \"owner\": new_experience.owner,\n",
    "                \"type\": new_experience.type,\n",
    "                \"transfer_date\": str(datetime.now())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        records.edit_features(adds=[adds])\n",
    "    \n",
    "    print(f\"Transfer of {new_experience.title} to folder {fldr_name} complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLONING STARTS HERE (RERUN FROM HERE)\n",
    "#### Run this section each time you change the item id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = destination.content.get(CATALOG_ID)\n",
    "catalog = catalog.tables[0]\n",
    "\n",
    "destination.content.get(CATALOG_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_origin = origin.content.get(ITEM_ID)\n",
    "\n",
    "print(f\"You are attempting to clone {item_origin.title}: \")\n",
    "item_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign item to origin transfer user\n",
    "if item_origin.owner != ORIGIN_TRANSFER_USER and MOVE_ITEMS:\n",
    "    item_origin.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "\n",
    "# decide on appropriate workflow for item\n",
    "if item_origin.type == \"StoryMap\":\n",
    "    destination.content.clone_items(items=[item_origin], folder=fldr_name)\n",
    "elif item_origin.type == \"Dashboard\":\n",
    "    dash_transfer(destination=destination, dash=item_origin, swizzle=True, records=catalog, logging=True)\n",
    "elif item_origin.type == \"Web Experience\":\n",
    "    exb_transfer(destination=destination, exb=item_origin, records=catalog, logging=True)\n",
    "else:\n",
    "    wc_transfer(destination=destination, items=[item_origin], records=catalog, logging=True)\n",
    "\n",
    "print(f\"Transfer of {item_origin.title} to folder {fldr_name} and its participating content complete. Please refresh your content page.\")\n",
    "\n",
    "#Move content to the final user that owns this and clean up the leftovers.\n",
    "if REASSIGN == True and MOVE_TO != destination.properties.user.username:\n",
    "    final_user = destination.users.get(MOVE_TO)\n",
    "    finl_fldr_name = get_or_create_folder(destination, item_origin.title, final_user.username)\n",
    "\n",
    "    mig_items = destination.users.get(destination.properties.user.username).items(folder=fldr_name)\n",
    "    \n",
    "    for item in mig_items:\n",
    "        #print(item.title)\n",
    "        item.reassign_to(final_user, target_folder=finl_fldr_name)\n",
    "        print(f'{item.title} was moved from {destination.properties.user.username} to {MOVE_TO}.')\n",
    "\n",
    "    # Check if the folder has any items\n",
    "    if len(destination.users.me.items(folder=finl_fldr_name)) == 0:\n",
    "        destination.content.delete_folder(finl_fldr_name, owner=destination.properties.user.username)\n",
    "        print(f'Folder {finl_fldr_name} has no content in it and was deleted.')\n",
    "    else:\n",
    "        print(f'Folder {finl_fldr_name} STILL has content and was NOT deleted.')\n",
    "        print(f'Script complete')\n",
    "else:\n",
    "    print(f'Script complete')"
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "8.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
