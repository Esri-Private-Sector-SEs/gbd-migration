{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURE HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CONSTANTS\"\"\" \n",
    "\n",
    "CATALOG_ID = \"\"\n",
    "ORIGIN_TRANSFER_USER = \"\"\n",
    "ORIGIN_URL = \"\"\n",
    "ITEM_ID = \"\" # INSERT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"IMPORTS\"\"\"\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.gis import Item\n",
    "from arcgis import __version__\n",
    "from arcgis.features import FeatureLayerCollection, Table\n",
    "from arcgis.mapping import WebMap\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "import uuid\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ITEM_COPY_PROPERTIES = ['title', 'type', 'typeKeywords', 'description', 'tags',\n",
    "                        'snippet', 'extent', 'spatialReference', 'name',\n",
    "                        'accessInformation', 'licenseInfo', 'culture', 'url']\n",
    "\n",
    "TEXT_BASED_ITEM_TYPES = frozenset(['Web Map', 'Feature Service', 'Map Service','Web Scene', 'Dashboard',\n",
    "                                   'Image Service', 'Feature Collection', \n",
    "                                   'Feature Collection Template',\n",
    "                                   'Web Mapping Application', 'Mobile Application', \n",
    "                                   'Symbol Set', 'Color Set',\n",
    "                                   'Windows Viewer Configuration'])\n",
    "\n",
    "FILE_BASED_ITEM_TYPES = frozenset(['File Geodatabase','CSV', 'Image', 'KML', 'Locator Package',\n",
    "                                  'Map Document', 'Shapefile', 'Microsoft Word', 'PDF',\n",
    "                                  'Microsoft Powerpoint', 'Microsoft Excel', 'Layer Package',\n",
    "                                  'Mobile Map Package', 'Geoprocessing Package', 'Scene Package',\n",
    "                                  'Tile Package', 'Vector Tile Package'])\n",
    "\n",
    "RELATIONSHIP_TYPES = frozenset(['Map2Service', 'WMA2Code',\n",
    "                                'Map2FeatureCollection', 'MobileApp2Code', 'Service2Data',\n",
    "                                'Service2Service'])\n",
    "\n",
    "_version = [int(i) for i in __version__.split('.')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIGURE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HARDCODED CONFIG FOR TESTING SM TRANSFER\n",
    "\n",
    "origin_pass = getpass(prompt=f\"Enter the password for user {ORIGIN_TRANSFER_USER}: \")\n",
    "\n",
    "# Establish origin and target GIS organizations\n",
    "print(\"Connecting ...\")\n",
    "origin = GIS(ORIGIN_URL, ORIGIN_TRANSFER_USER, origin_pass, expiration=9999)\n",
    "print(\"Connection Successful.\")\n",
    "\n",
    "destination = GIS(\"home\", expiration=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = destination.content.get(CATALOG_ID)\n",
    "catalog = catalog.tables[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_resources(item, save_path=None, file_name=None):\n",
    "    \"\"\"\n",
    "    Helper function, from https://developers.arcgis.com/python/samples/clone-storymap-version2/\n",
    "    Export's the data's resources as a zip file\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f'{item._gis._portal.resturl}content/users/{item._user_id}/items/{item.itemid}/resources/export'\n",
    "    if save_path is None:\n",
    "        save_path = tempfile.gettempdir()\n",
    "    if file_name is None:\n",
    "        file_name = f\"{uuid.uuid4().hex[:6]}.zip\"\n",
    "    params = {'f' : 'zip'}\n",
    "    con = item._gis._portal.con\n",
    "    resources = con.get(url, params=params,\n",
    "                        out_folder=save_path,\n",
    "                        file_name=file_name,\n",
    "                        try_json=False)\n",
    "    return resources\n",
    "\n",
    "def get_layer_item_ids(wm) -> list:\n",
    "    \"\"\"\n",
    "    Helper function from https://developers.arcgis.com/python/guide/cloning-content/\n",
    "    \n",
    "    Returns the related items in a webmap.\n",
    "    \n",
    "    Params:\n",
    "        wm (argis.gis.Item): Webmap item to be inspected.\n",
    "    Returns:\n",
    "        wm_id_list (list): List of related items in the web map.\n",
    "    \"\"\"\n",
    "    wmo = WebMap(wm)\n",
    "    wm_id_list = []\n",
    "    \n",
    "    for layer in wmo.layers:\n",
    "        try:\n",
    "            fsvc = FeatureLayerCollection(layer['url'][:-1], origin)\n",
    "            if not fsvc.properties['serviceItemId'] in wm_id_list:\n",
    "                wm_id_list.append(fsvc.properties['serviceItemId'])\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    return wm_id_list\n",
    "\n",
    "def iterate_all(iterable, returned=\"key\"):\n",
    "    # Credits: https://gist.github.com/PatrikHlobil/9d045e43fe44df2d5fd8b570f9fd78cc\n",
    "    \n",
    "    \"\"\"Returns an iterator that returns all keys or values\n",
    "       of a (nested) iterable.\n",
    "       \n",
    "       Arguments:\n",
    "           - iterable: <list> or <dictionary>\n",
    "           - returned: <string> \"key\" or \"value\"\n",
    "           \n",
    "       Returns:\n",
    "           - <iterator>\n",
    "    \"\"\"\n",
    "  \n",
    "    if isinstance(iterable, dict):\n",
    "        for key, value in iterable.items():\n",
    "            if returned == \"key\":\n",
    "                yield key\n",
    "            elif returned == \"value\":\n",
    "                if not (isinstance(value, dict) or isinstance(value, list)):\n",
    "                    yield value\n",
    "            else:\n",
    "                raise ValueError(\"'returned' keyword only accepts 'key' or 'value'.\")\n",
    "            for ret in iterate_all(value, returned=returned):\n",
    "                yield ret\n",
    "    elif isinstance(iterable, list):\n",
    "        for el in iterable:\n",
    "            for ret in iterate_all(el, returned=returned):\n",
    "                yield ret\n",
    "\n",
    "def get_dash_wm(dash) -> list:\n",
    "    \"\"\"\n",
    "    From https://developers.arcgis.com/python/guide/cloning-content/#helper-functions\n",
    "    \n",
    "    Returns a list of all Web Maps participating in a Dashboard. \n",
    "    \n",
    "    Arguments:\n",
    "        dash (item): Dashboard to return participating Web Maps from.\n",
    "    Returns:\n",
    "        (list): All Web Maps partipating in the dashboard. \n",
    "    \n",
    "    \"\"\"\n",
    "    return [origin.content.get(widget['itemId']) \n",
    "            for widget in dash.get_data()[\"desktopView\"]['widgets']\n",
    "            if widget['type'] == \"mapWidget\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_transfer(destination: GIS, \n",
    "                records: Table = None, \n",
    "                items: list = [], \n",
    "                logging: bool = False) -> list:\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs a web content transfer of items from an origin to destination AGOL. \n",
    "    \n",
    "    Arguments:\n",
    "        destination (arcgis.gis.GIS): Destination GIS for the given items\n",
    "        items (list): a list of Items to be transferred.\n",
    "        records (Table): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "    \"\"\"\n",
    "    \n",
    "    origin_to_destination_ids = {}\n",
    "    \n",
    "    for item in items:\n",
    "        if item.owner != ORIGIN_TRANSFER_USER:\n",
    "            item.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "    \n",
    "    item_titles = [item.title for item in items]\n",
    "    \n",
    "    print(\"Performing Web Content transfer for the following items: \")\n",
    "    for title in item_titles:\n",
    "        print(title)\n",
    "        \n",
    "    for item in items:\n",
    "        try:\n",
    "            if item.groupDesignations == 'livingatlas' or 'livingatlas' in item.groupDesignations:\n",
    "                print(f\"{item.title} is a Living Atlas item and therefore can only be referenced, not copied. Removing it from transfer.\")\n",
    "                return\n",
    "            if 'Requires Subscription' in item.typeKeywords:\n",
    "                print(f\"{item.title} is a premium subscription item and therefore can only be referenced, not copied. Removing it from transfer.\")\n",
    "                return\n",
    "            if 'utility.arcgis.com/usrsvcs' in item.url:\n",
    "                print(f\"{item.title} is a referenced  item and therefore can only be referenced, not copied. Removing it from transfer.\")\n",
    "                return\n",
    "        except TypeError:\n",
    "            continue\n",
    "    \n",
    "    for item in items:\n",
    "        if item.id == ITEM_ID:\n",
    "            destination.content.create_folder(item.title)\n",
    "                            \n",
    "    destination_items = destination.content.clone_items(items, folder=item.title)\n",
    "    \n",
    "    print(\"Item(s) cloned successfully. Updating tags ... \")\n",
    "    now = datetime.now()\n",
    "    tag = f\"src_{origin.properties['urlKey']}_{now.month}/{now.day}/{now.year}-{now.hour}:{now.minute}\"\n",
    "    \n",
    "    for item in destination_items:\n",
    "        item.update({'tags': tag})\n",
    "    for item, destitem in zip(items, destination_items):\n",
    "        destitem.update({'tags': item.tags})\n",
    "        \n",
    "    # build origin to destination map and memoize to catalog\n",
    "    origin_item_index = 0\n",
    "    for destination_item in destination_items:            \n",
    "        origin_to_destination_ids[item.id] = destination_item.id\n",
    "        \n",
    "        if item.id == ITEM_ID:\n",
    "            destination_item.move(destination_item.title) \n",
    "                    \n",
    "        if logging:   \n",
    "             \n",
    "            adds = {\"attributes\":\n",
    "                {\n",
    "                    \"source_id\": items[origin_item_index].id,\n",
    "                    \"destination_id\": destination_item.id,\n",
    "                    \"title\": destination_item.title,\n",
    "                    \"owner\": destination_item.owner,\n",
    "                    \"transfer_date\": str(datetime.now())\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            records.edit_features(adds=[adds])\n",
    "        \n",
    "        origin_item_index += 1\n",
    "        \n",
    "    print(\"Web Content Transfer complete.\")\n",
    "    \n",
    "    for item in destination_items:\n",
    "        try:\n",
    "            children = get_layer_item_ids(wm=item)\n",
    "            for child in children:\n",
    "                child_item = destination.content.get(child)\n",
    "                child_item.move(item.title)\n",
    "        except TypeError:\n",
    "            continue\n",
    "    \n",
    "    return destination_items\n",
    "    \n",
    "def dash_transfer(destination: GIS, \n",
    "                  dash: Item, \n",
    "                  swizzle: bool = True, \n",
    "                  records: Table = None, \n",
    "                  logging: bool = False) -> None:\n",
    "    \n",
    "    \"\"\"    \n",
    "    Performs a web content transfer of a dashboard to destination AGOL.\n",
    "    \n",
    "    Arguments:\n",
    "        destination (GIS): Destination GIS for the given Dashboard\n",
    "        dash (Item): A Dashboard item in the origin GIS\n",
    "        swizzle (bool): If True, enables JSON swizzling to map keys to values. Future proofing for ArcGIS API 2.2 release.\n",
    "        records (Table): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "    \"\"\"\n",
    "        \n",
    "    dash_elements = get_dash_wm(dash=dash)\n",
    "    wm_items = {} # origin to destination ids\n",
    "    \n",
    "    if dash.owner != ORIGIN_TRANSFER_USER:\n",
    "        dash.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "    \n",
    "    try:     \n",
    "        if dash.groupDesignations == 'livingatlas':\n",
    "            print(f\"{item.title} is a Living Atlas item and therefore can only be referenced, not copied. Aborting this dash transfer.\")\n",
    "            return\n",
    "        if 'Requires Subscription' in dash.typeKeywords:\n",
    "            print(f\"{item.title} is a premium subscription item and therefore can only be referenced, not copied. Aborting this dash transfer.\")\n",
    "            return\n",
    "    except TypeError:\n",
    "        pass\n",
    "            \n",
    "    print(f\"Creating destination folder for dashboard {dash.title} ...\")\n",
    "    destination.content.create_folder(dash.title)\n",
    "    \n",
    "    for ele in dash_elements:\n",
    "        \n",
    "        if ele.owner != ORIGIN_TRANSFER_USER:\n",
    "            ele.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "        \n",
    "        \"\"\"\n",
    "        if logging:\n",
    "            \n",
    "            records_df = pd.DataFrame.spatial.from_layer(records)\n",
    "            \n",
    "            if ele.id in records_df['source_id'].unique():\n",
    "                try:\n",
    "                    ele_dest_id  = records_df.loc[records_df['source_id'] == ele.id, 'destination_id'].values[0]\n",
    "                    wm_items[ele.id] = ele_dest_id\n",
    "                    destination_item = destination.content.get(ele_dest_id)\n",
    "                    destination_item.move(dash.title)\n",
    "                except IndexError:\n",
    "                    print(f\"Failed to transfer {ele.title}. Item may already exist in destination.\")\n",
    "                    continue\n",
    "        \"\"\"\n",
    "                    \n",
    "        # if the item participating in the dashboard has not yet been cloned: \n",
    "        try:\n",
    "            print(f\"Transferring {ele.title} to destination org, moving to Web Content transfer workflow ... \")\n",
    "            wc = wc_transfer(destination=destination, items=[ele])\n",
    "            web_map_dest = [item.id for item in wc if item.type == \"Web Map\"]\n",
    "            wm_items[ele.id] = web_map_dest[0]\n",
    "            for item in wc:\n",
    "                print(f\"Moving {item.title} to folder {dash.title} ... \")\n",
    "                item.move(dash.title)\n",
    "                \n",
    "                \"\"\"\n",
    "                ### Deprecating, as this is already done recursively within the wc_transfer function... \n",
    "                \n",
    "                if logging:\n",
    "                    \n",
    "                    key_list = list(wm_items.keys())\n",
    "                    val_list = list(wm_items.values())\n",
    "                    position = val_list.index(destination_item.id)\n",
    "                    \n",
    "                    new_record = pd.DataFrame({\"source_id\": key_list[position],\n",
    "                        \"destination_id\": item.id,\n",
    "                        \"title\": item.title,\n",
    "                        \"owner\": item.owner})\n",
    "                    records_table.edit_features(adds=new_record)\n",
    "                \"\"\"\n",
    "        \n",
    "        except IndexError:\n",
    "            print(f\"Item {ele.title} has already been transferred, applying destination-side edits ... \")\n",
    "            ele_from_search = destination.content.search(query=f\"typekeywords:source-{ele.id}\")[0]\n",
    "            wm_items[ele.id] = ele_from_search.id\n",
    "            ele_from_search.move(dash.title)\n",
    "\n",
    "    print(f\"Participating items handled, transferring dashboard {dash.title} ... \")\n",
    "\n",
    "    if swizzle == False:\n",
    "        dest_dash = destination.content.clone_items(items=[dash], item_mapping=wm_items, folder=dash.title)\n",
    "    else:\n",
    "        dest_dash = destination.content.clone_items(items=[dash], folder=dash.title)\n",
    "\n",
    "    \n",
    "    now = datetime.now()\n",
    "    tag = f\"src_{origin.properties['urlKey']}_{now.month}/{now.day}/{now.year}-{now.hour}:{now.minute}\"\n",
    "\n",
    "    for item in dest_dash:\n",
    "        item.update({'tags': tag})\n",
    "        item.update({'tags': dash.tags})\n",
    "    \n",
    "    if logging:\n",
    "        \n",
    "        adds = {\"attributes\":\n",
    "            {\n",
    "                \"source_id\": dash.id,\n",
    "                \"destination_id\": dest_dash[0].id,\n",
    "                \"title\": dest_dash[0].title,\n",
    "                \"owner\": dest_dash[0].owner,\n",
    "                \"transfer_date\": str(datetime.now())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        records.edit_features(adds=[adds])\n",
    "        \n",
    "    if swizzle:\n",
    "        # Swizzle the old and new IDs\n",
    "        cloned_dash = dest_dash[0]\n",
    "        dash_json = cloned_dash.get_data()\n",
    "        dash_str = json.dumps(dash_json)\n",
    "        \n",
    "        for key, val in wm_items.items():\n",
    "            dash_str = dash_str.replace(key, val)\n",
    "        \n",
    "        updated_data = json.loads(dash_str)\n",
    "\n",
    "        cloned_dash.update(item_properties = {}, data = updated_data)\n",
    "\n",
    "    print(f\"Dashboard clone successful. Refresh your content page.\")\n",
    "\n",
    "def sm_transfer(destination: GIS,  \n",
    "                item: Item,\n",
    "                records: Table = None, \n",
    "                logging : bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Adapted code sample from https://developers.arcgis.com/python/samples/clone-storymap-version2/\n",
    "    \n",
    "    Transfer protocol for Story Maps and their web content items. Does not call copy_items() as protocol is different for this content.\n",
    "    \n",
    "    Arguments:\n",
    "        destination (GIS): Destination GIS for the origin item.\n",
    "        item (Item): Story Map item to transfer from the origin.\n",
    "        records (Table): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    story_map = item\n",
    "    \n",
    "    orig_thumbnail = story_map.download_thumbnail()\n",
    "    \n",
    "    destination.content.create_folder(story_map.title)    \n",
    "    \n",
    "    # check version to apply relevant protocol\n",
    "    if _version <= [1, 8, 2]:\n",
    "        resource = export_resources(item=story_map)\n",
    "    else:\n",
    "        resource = story_map.resources.export()\n",
    "\n",
    "    # get story map item data from json to store related maps\n",
    "    story_map_json = story_map.get_data(try_json=True)\n",
    "\n",
    "    web_maps = set([v['data']['itemId'] for k, v in story_map_json['resources'].items() \\\n",
    "            if v['type'].lower().find('webmap')>-1])\n",
    "    express_maps = set([v['data']['itemId'] for k, v in story_map_json['resources'].items() \\\n",
    "            if v['type'].lower().find('expressmap')>-1])\n",
    "\n",
    "\n",
    "    webmap_mapper = {} # keys are origin IDs, values are destination IDs\n",
    "    for wm in web_maps:\n",
    "        webmap_to_copy = origin.content.get(wm)\n",
    "        \n",
    "        if webmap_to_copy == None:\n",
    "            print(f\"Webmap Item {wm.title} in Storymap not found in the org. Skipping...\")\n",
    "            continue\n",
    "        else:    \n",
    "            \n",
    "            \"\"\"\n",
    "            if logging:\n",
    "                \n",
    "                records_table = records.tables[0]\n",
    "                records_df = pd.DataFrame.spatial.from_layer(records_table)\n",
    "                \n",
    "                if webmap_to_copy.id in records_df['source_id'].unique():\n",
    "                    webmap_destination_id = records_df.loc[records_df['source_id'] == webmap_to_copy.id, 'destination_id']\n",
    "                    webmap_mapper[webmap_to_copy.id] = webmap_destination_id\n",
    "            else:\n",
    "            \"\"\"\n",
    "            \n",
    "            cloned_webmaps = destination.content.clone_items([webmap_to_copy])\n",
    "            webmap_mapper[webmap_to_copy.id] = [i for i in cloned_webmaps if i.type == 'Web Map'][0].id\n",
    "\n",
    "            # memoize tranfer to catalog\n",
    "            if logging:\n",
    "                \n",
    "                adds = {\"attributes\":\n",
    "                    {\n",
    "                        \"source_id\": webmap_to_copy.id,\n",
    "                        \"destination_id\": webmap_mapper[webmap_to_copy.id],\n",
    "                        \"title\": webmap_to_copy.title,\n",
    "                        \"owner\": webmap_to_copy.owner,\n",
    "                        \"type\": webmap_to_copy.type,\n",
    "                        \"transfer_date\": str(datetime.now())\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                records.edit_features(adds=[adds])\n",
    "                \n",
    "            for wm in cloned_webmaps:\n",
    "                wm.move(story_map.title)\n",
    "        \n",
    "    # remap the old itemid to the new one\n",
    "    story_map_text = json.dumps(story_map_json)\n",
    "\n",
    "    for key, val in webmap_mapper.items():\n",
    "        story_map_text = story_map_text.replace(key, val)\n",
    "\n",
    "    new_item = destination.content.add({'type' : story_map.type,\n",
    "                             'tags' : story_map.tags,\n",
    "                             'title' : story_map.title,\n",
    "                             'description' : story_map.description,\n",
    "                             'typeKeywords' : story_map.typeKeywords,\n",
    "                             'extent' : story_map.extent,\n",
    "                             'text' :story_map_text}\n",
    "                            )\n",
    "\n",
    "    # bring in the storymap resources exported to a zip archive earlier\n",
    "    new_item.resources.add(resource, archive=True)\n",
    "\n",
    "    # update the url\n",
    "    new_item.update({'url': story_map.url.replace(story_map.id, new_item.id)})\n",
    "    new_item.update(thumbnail=orig_thumbnail)\n",
    "    new_item.move(story_map.title)\n",
    "    \n",
    "    if logging:\n",
    "    \n",
    "        adds = {\"attributes\":\n",
    "            {\n",
    "                \"source_id\": item.id,\n",
    "                \"destination_id\": new_item[0].id,\n",
    "                \"title\": new_item[0].title,\n",
    "                \"owner\": new_item[0].owner,\n",
    "                \"type\": new_item[0].type,\n",
    "                \"transfer_date\": str(datetime.now())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        records.edit_features(adds=[adds])\n",
    "    \n",
    "    print(f\"StoryMap transfer complete. You can visit it at {new_item.homepage}\")\n",
    "\n",
    "def transfer():\n",
    "    \"\"\"\n",
    "    Runs the appropriate transfer function for the Item associated with the ITEM_ID global at the top of the notebook.\n",
    "    \"\"\"\n",
    "    \n",
    "    item_origin = origin.content.get(ITEM_ID)\n",
    "    \n",
    "    # reassign item to origin transfer user\n",
    "    if item_origin.owner != ORIGIN_TRANSFER_USER:\n",
    "        item_origin.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "    \n",
    "    # decide on appropriate workflow for item\n",
    "    if item_origin.type == \"StoryMap\":\n",
    "        sm_transfer(destination=destination, item=item_origin)\n",
    "    elif item_origin.type == \"Dashboard\":\n",
    "        dash_transfer(destination=destination, dash=item_origin, swizzle=True)\n",
    "    else:\n",
    "        wc_transfer(destination=destination, items=[item_origin])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer()"
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "8.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
