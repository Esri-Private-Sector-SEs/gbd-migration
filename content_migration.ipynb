{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURE HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CONSTANTS\"\"\" \n",
    "\n",
    "CATALOG_ID = \"67d3126d49cb45cc962e5775812dadd4\"\n",
    "ORIGIN_TRANSFER_USER = \"bankcomm\"\n",
    "ORIGIN_URL = \"https://banking.maps.arcgis.com/\"\n",
    "ITEM_ID = \"ce97c0e24b8140bd94277a1a29f8ce39\" # INSERT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"IMPORTS\"\"\"\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.gis import Item\n",
    "from arcgis.gis import ContentManager\n",
    "from arcgis import __version__\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "from arcgis.mapping import WebMap\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ITEM_COPY_PROPERTIES = ['title', 'type', 'typeKeywords', 'description', 'tags',\n",
    "                        'snippet', 'extent', 'spatialReference', 'name',\n",
    "                        'accessInformation', 'licenseInfo', 'culture', 'url']\n",
    "\n",
    "TEXT_BASED_ITEM_TYPES = frozenset(['Web Map', 'Feature Service', 'Map Service','Web Scene', 'Dashboard',\n",
    "                                   'Image Service', 'Feature Collection', \n",
    "                                   'Feature Collection Template',\n",
    "                                   'Web Mapping Application', 'Mobile Application', \n",
    "                                   'Symbol Set', 'Color Set',\n",
    "                                   'Windows Viewer Configuration'])\n",
    "\n",
    "FILE_BASED_ITEM_TYPES = frozenset(['File Geodatabase','CSV', 'Image', 'KML', 'Locator Package',\n",
    "                                  'Map Document', 'Shapefile', 'Microsoft Word', 'PDF',\n",
    "                                  'Microsoft Powerpoint', 'Microsoft Excel', 'Layer Package',\n",
    "                                  'Mobile Map Package', 'Geoprocessing Package', 'Scene Package',\n",
    "                                  'Tile Package', 'Vector Tile Package'])\n",
    "\n",
    "RELATIONSHIP_TYPES = frozenset(['Map2Service', 'WMA2Code',\n",
    "                                'Map2FeatureCollection', 'MobileApp2Code', 'Service2Data',\n",
    "                                'Service2Service'])\n",
    "\n",
    "_version = [int(i) for i in __version__.split('.')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIGURE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the password for user bankcomm: ········\n",
      "Connecting ...\n",
      "Connection Successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/arcgis/gis/__init__.py:703: UserWarning: You are logged on as fsi_transfer with an administrator role, proceed with caution.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### HARDCODED CONFIG FOR TESTING SM TRANSFER\n",
    "\n",
    "origin_pass = getpass(prompt=f\"Enter the password for user {ORIGIN_TRANSFER_USER}: \")\n",
    "\n",
    "# Establish origin and target GIS organizations\n",
    "print(\"Connecting ...\")\n",
    "origin = GIS(ORIGIN_URL, ORIGIN_TRANSFER_USER, origin_pass, expiration=9999)\n",
    "print(\"Connection Successful.\")\n",
    "\n",
    "destination = GIS(\"home\", expiration=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/arcgis/gis/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m  13199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 13200\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  13201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tables'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27/3402962783.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcatalog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCATALOG_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcatalog_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcatalog_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/arcgis/gis/__init__.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m  13172\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13173\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tables\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 13174\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tables\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tables\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  13175\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13176\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0m_common_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DisableLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/arcgis/gis/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m  13202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hydrated\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13203\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hydrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 13204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  13205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13206\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tables'"
     ]
    }
   ],
   "source": [
    "catalog = destination.content.get(CATALOG_ID)\n",
    "if catalog.type == \"CSV\":    \n",
    "    print(f\"Catalog is of type CSV but needs to be a Feature Table. Skipping...\")\n",
    "else:\n",
    "    catalog_table = catalog.tables[0]\n",
    "    catalog_df = pd.DataFrame.spatial.from_layer(catalog.tables[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_resources(item, save_path=None, file_name=None):\n",
    "    \"\"\"\n",
    "    Helper function, from https://developers.arcgis.com/python/samples/clone-storymap-version2/\n",
    "    Export's the data's resources as a zip file\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f'{item._gis._portal.resturl}content/users/{item._user_id}/items/{item.itemid}/resources/export'\n",
    "    if save_path is None:\n",
    "        save_path = tempfile.gettempdir()\n",
    "    if file_name is None:\n",
    "        file_name = f\"{uuid.uuid4().hex[:6]}.zip\"\n",
    "    params = {'f' : 'zip'}\n",
    "    con = item._gis._portal.con\n",
    "    resources = con.get(url, params=params,\n",
    "                        out_folder=save_path,\n",
    "                        file_name=file_name,\n",
    "                        try_json=False)\n",
    "    return resources\n",
    "\n",
    "def get_layer_item_ids(wm) -> list:\n",
    "    \"\"\"\n",
    "    Helper function from https://developers.arcgis.com/python/guide/cloning-content/\n",
    "    \n",
    "    Returns the related items in a webmap.\n",
    "    \n",
    "    Params:\n",
    "        wm (argis.gis.Item): Webmap item to be inspected.\n",
    "    Returns:\n",
    "        wm_id_list (list): List of related items in the web map.\n",
    "    \"\"\"\n",
    "    wmo = WebMap(wm)\n",
    "    wm_id_list = []\n",
    "    \n",
    "    for layer in wmo.layers:\n",
    "        try:\n",
    "            fsvc = FeatureLayerCollection(layer['url'][:-1], origin)\n",
    "            if not fsvc.properties['serviceItemId'] in wm_id_list:\n",
    "                wm_id_list.append(fsvc.properties['serviceItemId'])\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    return wm_id_list\n",
    "\n",
    "def iterate_all(iterable, returned=\"key\"):\n",
    "    # Credits: https://gist.github.com/PatrikHlobil/9d045e43fe44df2d5fd8b570f9fd78cc\n",
    "    \n",
    "    \"\"\"Returns an iterator that returns all keys or values\n",
    "       of a (nested) iterable.\n",
    "       \n",
    "       Arguments:\n",
    "           - iterable: <list> or <dictionary>\n",
    "           - returned: <string> \"key\" or \"value\"\n",
    "           \n",
    "       Returns:\n",
    "           - <iterator>\n",
    "    \"\"\"\n",
    "  \n",
    "    if isinstance(iterable, dict):\n",
    "        for key, value in iterable.items():\n",
    "            if returned == \"key\":\n",
    "                yield key\n",
    "            elif returned == \"value\":\n",
    "                if not (isinstance(value, dict) or isinstance(value, list)):\n",
    "                    yield value\n",
    "            else:\n",
    "                raise ValueError(\"'returned' keyword only accepts 'key' or 'value'.\")\n",
    "            for ret in iterate_all(value, returned=returned):\n",
    "                yield ret\n",
    "    elif isinstance(iterable, list):\n",
    "        for el in iterable:\n",
    "            for ret in iterate_all(el, returned=returned):\n",
    "                yield ret\n",
    "\n",
    "def get_dash_wm(dash) -> list:\n",
    "    \"\"\"\n",
    "    From https://developers.arcgis.com/python/guide/cloning-content/#helper-functions\n",
    "    \n",
    "    Returns a list of all Web Maps participating in a Dashboard. \n",
    "    \n",
    "    Arguments:\n",
    "        dash (item): Dashboard to return participating Web Maps from.\n",
    "    Returns:\n",
    "        (list): All Web Maps partipating in the dashboard. \n",
    "    \n",
    "    \"\"\"\n",
    "    return [origin.content.get(widget['itemId']) \n",
    "            for widget in dash.get_data()[\"desktopView\"]['widgets']\n",
    "            if widget['type'] == \"mapWidget\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_transfer(destination: GIS, items=[], records=catalog, logging=False) -> list:\n",
    "    \"\"\"\n",
    "    Performs a web content transfer of items from an origin to destination AGOL. \n",
    "    \n",
    "    Arguments:\n",
    "        destination (arcgis.gis.GIS): Destination GIS for the given items\n",
    "        items (list): a list of Items to be transferred.\n",
    "        records (item): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "    \"\"\"\n",
    "    \n",
    "    origin_to_destination_ids = {}\n",
    "    \n",
    "    for item in items:\n",
    "        if item.owner != ORIGIN_TRANSFER_USER:\n",
    "            item.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "    \n",
    "    item_titles = [item.title for item in items]\n",
    "    \n",
    "    print(\"Performing Web Content transfer for the following items: \")\n",
    "    for title in item_titles:\n",
    "        print(title)\n",
    "        \n",
    "    for item in items:\n",
    "        try:\n",
    "            if item.groupDesignations == 'livingatlas' or 'livingatlas' in item.groupDesignations:\n",
    "                print(f\"{item.title} is a Living Atlas item and therefore can only be referenced, not copied. Removing it from transfer.\")\n",
    "                return\n",
    "            if 'Requires Subscription' in item.typeKeywords:\n",
    "                print(f\"{item.title} is a premium subscription item and therefore can only be referenced, not copied. Removing it from transfer.\")\n",
    "                return\n",
    "        except TypeError:\n",
    "            continue\n",
    "                            \n",
    "    destination_items = destination.content.clone_items(items)\n",
    "    \n",
    "    print(\"Item(s) cloned successfully. Updating tags ... \")\n",
    "    now = datetime.now()\n",
    "    tag = f\"src_{origin.properties['urlKey']}_{now.month}/{now.day}/{now.year}-{now.hour}:{now.minute}\"\n",
    "    \n",
    "    for item in destination_items:\n",
    "        item.update({'tags': tag})\n",
    "        \n",
    "    # build origin to destination map and memoize to catalog\n",
    "    origin_item_index = 0\n",
    "    for destination_item in destination_items:            \n",
    "        origin_to_destination_ids[item.id] = destination_item.id \n",
    "        \n",
    "        if logging:   \n",
    "            records_table = records.tables[0]\n",
    "             \n",
    "            new_record = pd.DataFrame({\"source_id\": [items[origin_item_index].id],\n",
    "                            \"destination_id\": destination_item.id,\n",
    "                            \"title\": destination_item.title,\n",
    "                            \"owner\": destination_item.owner})\n",
    "            records_table.edit_features(adds=new_record)\n",
    "        \n",
    "        origin_item_index += 1\n",
    "        \n",
    "    print(\"Web Content Transfer complete.\")\n",
    "    \n",
    "    return destination_items\n",
    "    \n",
    "def dash_transfer(destination: GIS, dash: Item, swizzle=False, records=catalog, logging=False) -> None:\n",
    "    \"\"\"    \n",
    "    Performs a web content transfer of a dashboard to destination AGOL.\n",
    "    \n",
    "    Arguments:\n",
    "        destination (GIS): Destination GIS for the given Dashboard\n",
    "        dash (Item): A Dashboard item in the origin GIS\n",
    "        swizzle (bool): If True, enables JSON swizzling to map keys to values. Future proofing for ArcGIS API 2.2 release.\n",
    "        records (item): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "    \"\"\"\n",
    "        \n",
    "    dash_elements = get_dash_wm(dash=dash)\n",
    "    wm_items = {} # origin to destination ids\n",
    "    \n",
    "    if dash.owner != ORIGIN_TRANSFER_USER:\n",
    "        dash.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "        \n",
    "    if dash.groupDesignations == 'livingatlas':\n",
    "        print(f\"{item.title} is a Living Atlas item and therefore can only be referenced, not copied. Aborting this dash transfer.\")\n",
    "        return\n",
    "    if 'Requires Subscription' in dash.typeKeywords:\n",
    "        print(f\"{item.title} is a premium subscription item and therefore can only be referenced, not copied. Aborting this dash transfer.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Creating destination folder for dashboard {dash.title} ...\")\n",
    "    destination.content.create_folder(dash.title)\n",
    "    \n",
    "    for ele in dash_elements:\n",
    "        \n",
    "        if ele.owner != ORIGIN_TRANSFER_USER:\n",
    "            ele.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "        \n",
    "        # check if the item exists in catalog and use shortcut if so\n",
    "        if logging:\n",
    "            \n",
    "            records_table = records.tables[0]\n",
    "            records_df = pd.DataFrame.spatial.from_layer(records_table)\n",
    "            \n",
    "            if ele.id in records_df['source_id'].unique():\n",
    "                try:\n",
    "                    ele_dest_id  = records_df.loc[records_df['source_id'] == ele.id, 'destination_id'].values[0]\n",
    "                    wm_items[ele.id] = ele_dest_id\n",
    "                    destination_item = destination.content.get(ele_dest_id)\n",
    "                    destination_item.move(dash.title)\n",
    "                except IndexError:\n",
    "                    print(f\"Failed to transfer {ele.title}. Item may already exist in destination.\")\n",
    "                    continue\n",
    "\n",
    "        # if the item participating in the dashboard has not yet been cloned: \n",
    "        else:\n",
    "            try:\n",
    "                print(f\"Transferring {ele.title} to destination org, moving to Web Content transfer workflow ... \")\n",
    "                wc = wc_transfer(destination=destination, items=[ele])\n",
    "                web_map_dest = [item.id for item in wc if item.type == \"Web Map\"]\n",
    "                wm_items[ele.id] = web_map_dest[0]\n",
    "                for item in wc:\n",
    "                    print(f\"Moving {item.title} to folder {dash.title} ... \")\n",
    "                    item.move(dash.title)\n",
    "                    \n",
    "                    if logging:\n",
    "                        key_list = list(wm_items.keys())\n",
    "                        val_list = list(wm_items.values())\n",
    "                        position = val_list.index(destination_item.id)\n",
    "                        \n",
    "                        new_record = pd.DataFrame({\"source_id\": key_list[position],\n",
    "                            \"destination_id\": item.id,\n",
    "                            \"title\": item.title,\n",
    "                            \"owner\": item.owner})\n",
    "                        records_table.edit_features(adds=new_record)\n",
    "            \n",
    "            except IndexError:\n",
    "                print(f\"Item {ele.title} has already been transferred, applying destination-side edits ... \")\n",
    "                ele_from_search = destination.content.search(query=f\"typekeywords:source-{ele.id}\")[0]\n",
    "                wm_items[ele.id] = ele_from_search.id\n",
    "                ele_from_search.move(dash.title)\n",
    "    \n",
    "    print(f\"Participating items handled, transferring dashboard {dash.title} ... \")\n",
    "    try:\n",
    "        dest_dash = destination.content.clone_items(items=[dash], item_mapping=wm_items, folder=dash.title)\n",
    "    except Exception:\n",
    "        print(\"Issue with item mapping. Continuing anyways because that's responsible. Please check contents after.\")\n",
    "    \n",
    "    now = datetime.now()\n",
    "    tag = f\"src_{origin.properties['urlKey']}_{now.month}/{now.day}/{now.year}-{now.hour}:{now.minute}\"\n",
    "\n",
    "    for dash in dest_dash:\n",
    "        dash.update({'tags': tag})\n",
    "    \n",
    "    if logging:\n",
    "        new_record = pd.DataFrame({\"source_id\": dash.id,\n",
    "                            \"destination_id\": dest_dash[0].id,\n",
    "                            \"title\": dest_dash[0].title,\n",
    "                            \"owner\": dest_dash[0].owner})\n",
    "        records_table.edit_features(adds=new_record)\n",
    "        \n",
    "    if swizzle:\n",
    "        # Swizzle the old and new IDs\n",
    "        cloned_dash = dest_dash[0]\n",
    "        dash_json = cloned_dash.get_data()\n",
    "        dash_str = json.dumps(dash_json)\n",
    "        \n",
    "        for key, val in wm_items.items():\n",
    "            dash_str = dash_str.replace(key, val)\n",
    "        \n",
    "        updated_data = json.loads(dash_str)\n",
    "\n",
    "        cloned_dash.update(item_properties = {}, data = updated_data)\n",
    "\n",
    "    print(f\"Dashboard clone successful. Refresh your content page.\")\n",
    "\n",
    "def sm_transfer(destination: GIS, item: Item, records=catalog, logging=False) -> None:\n",
    "    \"\"\"\n",
    "    Adapted code sample from https://developers.arcgis.com/python/samples/clone-storymap-version2/\n",
    "    \n",
    "    Transfer protocol for Story Maps and their web content items. Does not call copy_items() as protocol is different for this content.\n",
    "    \n",
    "    Arguments:\n",
    "        destination (GIS): Destination GIS for the origin item.\n",
    "        item (Item): Story Map item to transfer from the origin.\n",
    "        records (item): Hosted Table item to memoize transfers to. Must be passed if logging=True\n",
    "        logging (bool): If True, enables catalog memoization, pushing a transfer record to a Hosted Table in AGOL.  \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    story_map = item\n",
    "    \n",
    "    orig_thumbnail = story_map.download_thumbnail()\n",
    "    \n",
    "    destination.content.create_folder(story_map.title)    \n",
    "    \n",
    "    # check version to apply relevant protocol\n",
    "    if _version <= [1, 8, 2]:\n",
    "        resource = export_resources(item=story_map)\n",
    "    else:\n",
    "        resource = story_map.resources.export()\n",
    "\n",
    "    # get story map item data from json to store related maps\n",
    "    story_map_json = story_map.get_data(try_json=True)\n",
    "\n",
    "    web_maps = set([v['data']['itemId'] for k, v in story_map_json['resources'].items() \\\n",
    "            if v['type'].lower().find('webmap')>-1])\n",
    "    express_maps = set([v['data']['itemId'] for k, v in story_map_json['resources'].items() \\\n",
    "            if v['type'].lower().find('expressmap')>-1])\n",
    "\n",
    "\n",
    "    webmap_mapper = {} # keys are origin IDs, values are destination IDs\n",
    "    for wm in web_maps:\n",
    "        webmap_to_copy = origin.content.get(wm)\n",
    "        \n",
    "        if webmap_to_copy == None:\n",
    "            print(f\"Webmap Item {wm.title} in Storymap not found in the org. Skipping...\")\n",
    "            continue\n",
    "        else:    \n",
    "            # check if item has been tranferred, if no then duplicate, if yes point to content that already exists\n",
    "            if logging:\n",
    "                \n",
    "                records_table = records.tables[0]\n",
    "                records_df = pd.DataFrame.spatial.from_layer(records_table)\n",
    "                \n",
    "                if webmap_to_copy.id in records_df['source_id'].unique():\n",
    "                    webmap_destination_id = records_df.loc[records_df['source_id'] == webmap_to_copy.id, 'destination_id']\n",
    "                    webmap_mapper[webmap_to_copy.id] = webmap_destination_id\n",
    "            else:\n",
    "                cloned_webmaps = destination.content.clone_items([webmap_to_copy])\n",
    "                webmap_mapper[webmap_to_copy.id] = [i for i in cloned_webmaps if i.type == 'Web Map'][0].id\n",
    "\n",
    "                # memoize tranfer to catalog\n",
    "                if logging:\n",
    "                    new_record = pd.DataFrame({\"source_id\": [webmap_to_copy.id],\n",
    "                                            \"destination_id\": [webmap_mapper[webmap_to_copy.id]], # gets destination ID from corresponding origin ID\n",
    "                                            \"title\": [webmap_to_copy.title],\n",
    "                                            \"owner\": [webmap_to_copy.owner]})\n",
    "                    records_table.edit_features(adds=new_record)\n",
    "                    \n",
    "                for wm in cloned_webmaps:\n",
    "                    wm.move(story_map.title)\n",
    "        \n",
    "    # remap the old itemid to the new one\n",
    "    story_map_text = json.dumps(story_map_json)\n",
    "\n",
    "    for key, val in webmap_mapper.items():\n",
    "        story_map_text = story_map_text.replace(key, val)\n",
    "\n",
    "    new_item = destination.content.add({'type' : story_map.type,\n",
    "                             'tags' : story_map.tags,\n",
    "                             'title' : story_map.title,\n",
    "                             'description' : story_map.description,\n",
    "                             'typeKeywords' : story_map.typeKeywords,\n",
    "                             'extent' : story_map.extent,\n",
    "                             'text' :story_map_text}\n",
    "                            )\n",
    "\n",
    "    # bring in the storymap resources exported to a zip archive earlier\n",
    "    new_item.resources.add(resource, archive=True)\n",
    "\n",
    "    # update the url\n",
    "    new_item.update({'url': story_map.url.replace(story_map.id, new_item.id)})\n",
    "    new_item.update(thumbnail=orig_thumbnail)\n",
    "    new_item.move(story_map.title)\n",
    "    \n",
    "    print(f\"StoryMap transfer complete. You can visit it at {new_item.homepage}\")\n",
    "\n",
    "def transfer():\n",
    "    \"\"\"\n",
    "    Runs the appropriate transfer function for the Item associated with the ITEM_ID global at the top of the notebook.\n",
    "    \"\"\"\n",
    "    \n",
    "    item_origin = origin.content.get(ITEM_ID)\n",
    "    \n",
    "    # reassign item to origin transfer user\n",
    "    if item_origin.owner != ORIGIN_TRANSFER_USER:\n",
    "        item_origin.reassign_to(ORIGIN_TRANSFER_USER)\n",
    "    \n",
    "    # decide on appropriate workflow for item\n",
    "    if item_origin.type == \"StoryMap\":\n",
    "        sm_transfer(destination=destination, item=item_origin)\n",
    "    elif item_origin.type == \"Dashboard\":\n",
    "        dash_transfer(destination=destination, dash=item_origin, swizzle=True)\n",
    "    else:\n",
    "        wc_transfer(destination=destination, items=[item_origin])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating destination folder for dashboard Atlanta MSA Accessibility Dashboard ...\n",
      "Folder already exists.\n",
      "Transferring Atlanta MSA Map to destination org, moving to Web Content transfer workflow ... \n",
      "Performing Web Content transfer for the following items: \n",
      "Atlanta MSA Map\n",
      "Item(s) cloned successfully. Updating tags ... \n",
      "Web Content Transfer complete.\n",
      "Moving Atlanta MSA to folder Atlanta MSA Accessibility Dashboard ... \n",
      "Moving Atlanta MSA Map to folder Atlanta MSA Accessibility Dashboard ... \n",
      "Participating items handled, transferring dashboard Atlanta MSA Accessibility Dashboard ... \n",
      "Already existent or Living Atlas items excluded from cloning. Check info-level logs for details.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Item \"1521ca951b53454f8c31d89f2f991d11\" does not exist in the source portal",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27/3793353524.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_27/2653399150.py\u001b[0m in \u001b[0;36mtransfer\u001b[0;34m()\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0msm_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem_origin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mitem_origin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Dashboard\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mdash_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswizzle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mwc_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_origin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27/2653399150.py\u001b[0m in \u001b[0;36mdash_transfer\u001b[0;34m(destination, dash, swizzle, records, logging)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Participating items handled, transferring dashboard {dash.title} ... \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mdest_dash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdash\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwm_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/arcgis/gis/__init__.py\u001b[0m in \u001b[0;36mclone_items\u001b[0;34m(self, items, folder, item_extent, use_org_basemap, copy_data, copy_global_ids, search_existing_items, item_mapping, group_mapping, owner, preserve_item_id, **kwargs)\u001b[0m\n\u001b[1;32m   8560\u001b[0m             \u001b[0mwab_code_attach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy_code_attachment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8561\u001b[0m         )\n\u001b[0;32m-> 8562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeep_cloner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8564\u001b[0m     def bulk_update(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/arcgis/_impl/common/_clone.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/arcgis/_impl/common/_clone.py\u001b[0m in \u001b[0;36m_clone\u001b[0;34m(self, excecutor)\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \"\"\"\n\u001b[0;32m-> 1223\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clone_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mleaf_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_leaf_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/arcgis/_impl/common/_clone.py\u001b[0m in \u001b[0;36m_clone_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m                 raise Exception(\n\u001b[0m\u001b[1;32m   1134\u001b[0m                     'Item \"{0}\" does not exist in the source portal'.format(\n\u001b[1;32m   1135\u001b[0m                         \u001b[0moriginal_item_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Item \"1521ca951b53454f8c31d89f2f991d11\" does not exist in the source portal"
     ]
    }
   ],
   "source": [
    "transfer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "8.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
